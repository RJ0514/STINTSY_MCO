{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb94d1a1-2c72-4734-aed4-10c1b1090c84",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# STINTSY Major Course Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81d6ae-d979-40f2-8d78-d038dd3f01a5",
   "metadata": {},
   "source": [
    "*S12 - Ryan Jay Deculawan, Hyenne Audrey Lim, Viktoria Lila Sicuan*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4365c86-4bf7-411c-b8e0-b4f55050d31f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a4ca9",
   "metadata": {},
   "source": [
    "Soccer's extraordinary global appeal, with 3.5 billion supporters worldwide, cements its position as the most watched sport on the planet. Soccer creates a common passion that brings people from all walks of life together (The Most Popular Sports In The World, n.d.). This worldwide sport has the remarkable potential to cross cultural, language, and geographical borders, bringing people together from all walks of life. Fans congregate in their homes, bars, or stadiums to form a feeling of community and shared identity. Soccer's ongoing popularity stems from its capacity to bring together people of all ages and skill levels, making it more than simply a game but a celebration of athleticism, teamwork, and the universal spirit of competitiveness.\n",
    "\n",
    "Soccer's enormous commercial worth is clear in the huge sums it earns for numerous leagues throughout the world. Soccer leagues have the highest TV viewership of any sports league, which contributes greatly to the sport's economic supremacy. The World Cup, the flagship event, is the embodiment of this phenomena, easily outshining every other significant athletic event. The tremendous viewership and worldwide influence of the World Cup highlight soccer's power to captivate the collective interest and intrigue of audiences on an unprecedented scale, transforming it into more than simply a game but a global cultural phenomenon. Soccer's economic impact, paired with its exciting dynamics, solidifies it as a sporting superpower that crosses geographical and cultural barriers (The World’s Most Watched Sports, 2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939a712",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36dbb7",
   "metadata": {},
   "source": [
    "Home advantage, which occurs in all sports, including soccer, is caused by a mix of psychological and physiological variables. The presence of ardent supporters fosters a supportive and motivational environment for the home side while perhaps influencing referee decisions owing to crowd reactions. Furthermore, the physical and emotional exhaustion involved with travel for visiting teams contributes to the home edge. The familiarity with the particular qualities of the home field, like as pitch size and surface, further tilts the scale in favor of the home side. Home advantage is essentially a complicated interaction of crowd support, referee dynamics, travel-related obstacles, and field familiarity that shapes the competitive landscape of sports (Zheng, 2015).\n",
    "\n",
    "With this in mind, our objective is to investigate the feasibility of forecasting home advantage based on a snapshot of soccer matches. This project intends to emphasize the complex problems of applying modeling tools to real-life events, particularly in the dynamic environment of soccer matches. These machine learning models can help teams plan better strategies by offering insights into their opponents' strengths and weaknesses, such as knowing whether it is strategically better to play aggressively given the statistics of the match. Fans may also appreciate the game on a whole new level through the analysis of data and understanding the aspects that contribute to a team's success. Furthermore, predictive models can assist spectators in making better educated predictions about the outcome of a game, which can increase the enjoyment of watching the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36522c-4923-4d58-90f0-7644b24712d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Description of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fb74f-8a1d-4d0c-8274-124d3aa71107",
   "metadata": {},
   "source": [
    "To address the identified task, the Sports dataset was selected. This dataset contains 7000 random snapshots from soccer matches. This dataset was used as part of a [Kaggle Community Prediction Competition](https://www.kaggle.com/competitions/sports-trading-will-there-be-more-goals/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7c726-84a7-4aaf-99a0-14085002210c",
   "metadata": {},
   "source": [
    "One row in the dataset represents one snapshot of a match while one column represents one feature of a match. As mentioned, there are **7000 instances** (rows), and **21 features** (columns). The features of the dataset are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac7785-ac2a-4cc9-898f-1f4c1cb8f9de",
   "metadata": {},
   "source": [
    "1. `uuid` - The unique identifier of the snapshot\n",
    "2. `current_minute` - The current minute of the in-play match. The 15 minute half-time break is included so a match has a total of 105 minutes. A current_minute of 70 corresponds to the actual match time of 55.\n",
    "3. `home_score` - Goals scored by the home team as of this current_minute\n",
    "4. `away_score`– Goals scored by the away team as of this current_minute\n",
    "5. `home_yellow_cards` - Yellow cards given to the home team as of this current_minute\n",
    "6. `away_yellow_cards` - Yellow cards given to the away team as of this current_minute\n",
    "7. `home_red_cards` - Red cards given to the home team as of this current_minute\n",
    "8. `away_red_cards` - Red cards given to the away team as of this current_minute\n",
    "9. `home_attacks` - Attacks attempted by the home team as of this current_minute\n",
    "10. `away_attacks` - Attacks attempted by the away team as of this current_minute\n",
    "11. `home_dangerous_attacks` - Dangerous attacks attempted by the home team as of this current_minute\n",
    "12. `away_dangerous_attacks` - Dangerous attacks attempted by the away team as of this current_minute\n",
    "13. `home_corners` - Corners awarded to the home team as of this current_minute\n",
    "14. `away_corners` - Corners awarded to the away team as of this current_minute\n",
    "15. `home_off_target` - Shots that didn't have to be cleared by the goalkeeper that were attempted to the home team as of this current_minute\n",
    "16. `away_off_target` - Shots that didn't have to be cleared by the goalkeeper that were attempted to the away team as of this current_minute\n",
    "17. `home_on_target` - Shots that had to be cleared by the goalkeeper that were attempted to the home team as of this current_minute`\n",
    "18. `away_on_target` - Shots that had to be cleared by the goalkeeper that were attempted to the away team as of this current_minute`\n",
    "19. `home_possession` - How much ball possession in % did the home team have until this current_minute`\n",
    "20. `away_possession` - How much ball possession in % did the away team have until this current_minute`\n",
    "21. `final_delta` - The intended target value for each instance. Given that this dataset is from a competition, this column was provided as the value to be predicted for an instance's set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfea645-5ad4-4d0e-acb9-7771d6cfac9f",
   "metadata": {},
   "source": [
    "## 3. List of Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bab29a-9e5c-44dc-8ccb-0bf133afa645",
   "metadata": {},
   "source": [
    "The following are the libraries and modules used to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378037d8-a942-44c8-8358-2bbe9309016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69d729-f8c9-4663-b858-ccf8a5117846",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc781cb-e608-4121-a860-5c602696544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "data = pd.read_csv('sports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215f07e-2b66-49c6-98ac-c171c3effcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62a082-8c7e-4f85-8148-0c732cbc4213",
   "metadata": {},
   "source": [
    "Given that the `final_delta` and `uuid` columns do not contribute to the characterization of each soccer match timestamp, these are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86226506-6980-4144-b025-1aabeddaccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"uuid\", \"final_delta\"], axis=1, inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfd12a-cd63-49a0-a83f-f84e696b4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 14 instances where the current minute is <0. \n",
    "#Given that these are only 14, and our total data size is 7000, we can opt to remove them.\n",
    "\n",
    "#First: Collect the indexes of the to-be-removed rows\n",
    "indices = list(data[data['current_minute'] < 0].index)\n",
    "\n",
    "#Second: remove the rows using .drop \n",
    "data = data.drop(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96fe26-d9be-4166-a4b3-20850160d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets check, if these outliers are still present.\n",
    "data[data['current_minute'] < 0]\n",
    "#Hooray (dejk) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358548c0-c29c-4d27-9acc-46f4b3c38f27",
   "metadata": {},
   "source": [
    "TODO: *Perform preprocessing and cleaning; move dropping < 0 minute rows here etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f28394-c7c9-46c7-8c7f-41d3cf221c84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63509e-0668-4427-ad47-0c26ea5228d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculating for Central Tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d876729-7390-4b1e-9455-d42681fc51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_tendencies = pd.DataFrame({\n",
    "    'Mean': data.iloc[:, 1:].mean(),\n",
    "    'Median': data.iloc[:, 1:].median(),\n",
    "    'Mode': data.iloc[:, 1:].mode().iloc[0]\n",
    "})\n",
    "central_tendencies = central_tendencies.reset_index()\n",
    "central_tendencies = central_tendencies.rename(columns={'index': 'Feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020732f-f844-44d9-baa4-64b9e5b3c055",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_tendencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f500b2a-18bd-44c6-b59f-d648062011ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculating for Dispersion, Skewness, and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9b200-bad5-4309-88a0-91a95d74591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Insert purpose of these 3 \n",
    "    Dispersion\n",
    "        - \n",
    "        -\n",
    "    Skewness\n",
    "        - \n",
    "    Kurtosis\n",
    "        - \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41f132-fc57-4528-b32a-a6909ac3727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for variance and standard deviation\n",
    "dispersion_metrics = pd.DataFrame({\n",
    "    'Variance': data.iloc[:, 1:].var(),\n",
    "    'Standard Deviation': data.iloc[:, 1:].std(),\n",
    "    'Skewness': data.iloc[:, 1:].skew(),\n",
    "    'Kurtosis': data.iloc[:, 1:].kurt()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53046c4d-93cd-40fb-9484-eff413596377",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_metrics = dispersion_metrics.reset_index()\n",
    "dispersion_metrics = dispersion_metrics.rename(columns={'index': 'Feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a6816-1d00-4a2b-9e8d-cdaed933af83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e0088-3349-420b-b207-eb7203572029",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda817b-7ab9-4757-bc62-f701907e6403",
   "metadata": {},
   "source": [
    "Insert insights here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b2f635-d4e9-440e-9350-4d975cb69cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53593bdd-2612-4c1c-9a31-b44778448526",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[ (data['current_minute'] > 105)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c314c-eef8-455a-a931-b5fe997db42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Outliers\n",
    "data[data['current_minute'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff49f8f-a17d-4552-9ecc-3de11fc1953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "def plot_histogram(col_name, bin_count = 5):\n",
    "    data_for_hist = data[col_name]\n",
    "    plt.hist(data_for_hist, bins=bin_count, edgecolor='black')\n",
    "\n",
    "    # Add labels and a title\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of '+col_name)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    \n",
    "plot_histogram('current_minute',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7017d0-78ee-40be-b833-d7fac619a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def check_value_counts(col_name, df_name =\"\"):\n",
    "    if(type(col_name) == str):\n",
    "        value_counts = Counter(data[col_name])\n",
    "        print(col_name+\" value count:\")\n",
    "    else:\n",
    "        value_counts = Counter(col_name)\n",
    "        print(df_name+\" value count:\")\n",
    "    value_counts = value_counts.most_common()\n",
    "\n",
    "    # Display the counts\n",
    "    for value, count in value_counts:\n",
    "        print(f\"{value}: {count}\")\n",
    "        \n",
    "check_value_counts('home_red_cards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b87ad-547c-4726-91e1-f8bab50a16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_snapshot = data[['home_score','away_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b0c85-436f-4a44-9291-b07eed0e3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e3b6d-02ec-4694-bff1-02030e0e02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_snapshot.loc[:,('Difference')] = score_snapshot['home_score'] - score_snapshot['away_score'] \n",
    "score_snapshot.loc[:,('Difference')] = np.where(score_snapshot.loc[:,('Difference')] < 0, -1,\n",
    "                                       np.where(score_snapshot.loc[:,('Difference')] > 0, 1,\n",
    "                                                0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0dcb7-a47d-4e99-880e-c77ab9999c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a505351-27f4-4ab6-b1c3-f1a1c26a30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value_counts(score_snapshot['Difference'],\"Difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56899c7-f078-4a02-a64f-210d801f9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38652046-c906-44bc-88e2-cdd093b508f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the current minute, what is the average home score?\n",
    "test_df = data[['current_minute','home_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385c5db-0fb3-424e-b109-e7132e4a4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'current_minute' and calculate the average home score\n",
    "average_home_score = test_df.groupby('current_minute')['home_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64845333-918b-492d-8ed8-3d778905d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, the average football game lasts about 90 - 95 minutes. Depending on the circumstance -- referees can extend this time.\n",
    "#To give allowances to the number of games that are long but not too long, we need to find the optimal number of minutes that could capture games that extended.\n",
    "'''\n",
    "    We'll use 110 because from the 95 - 110 minute mark, there are about 1000+ entries (Confirm)\n",
    "    While games that pass the 110 mark, are 63 entries in total.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da638c00-0e1a-4806-9257-dfd38fdbbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'current_minute' values and the corresponding averages\n",
    "minutes = average_home_score[average_home_score.index <= 110].index\n",
    "average_scores = average_home_score[average_home_score.index <= 110].values\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(minutes, average_scores, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Current Minute')\n",
    "plt.ylabel('Average Home Score')\n",
    "plt.title('Average Home Score Over Time')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bba51-1051-4333-9200-59417411be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We could see that as the game progresses, the average score falls between 0 - 2 points.\n",
    "#We could also see that there are outliers where it flattens or drops significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfb05b-033f-4c19-a424-2d9f3158c7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e24e4d-fd8a-42fb-9826-5a99cc8faa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the current minute, what is the average home score?\n",
    "test_df = data[['current_minute','away_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475d334-45f3-4ed0-9ca1-5544251cf792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'current_minute' and calculate the average home score\n",
    "average_away_score = test_df.groupby('current_minute')['away_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f940e62c-b131-4268-a340-ca3a109283b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, the average football game lasts about 90 - 95 minutes. Depending on the circumstance -- referees can extend this time.\n",
    "#To give allowances to the number of games that are long but not too long, we need to find the optimal number of minutes that could capture games that extended.\n",
    "'''\n",
    "    We'll use 110 because from the 95 - 110 minute mark, there are about 1000+ entries (Confirm)\n",
    "    While games that pass the 110 mark, are 63 entries in total.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc77ccfe-e1c0-4f06-8e24-c0223ef12887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'current_minute' values and the corresponding averages\n",
    "minutes = average_away_score[average_away_score.index <= 110].index\n",
    "average_scores = average_away_score[average_away_score.index <= 110].values\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(minutes, average_scores, marker='o', linestyle='-')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Current Minute')\n",
    "plt.ylabel('Average Away Score')\n",
    "plt.title('Average Away Score Over Time')\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8dfd7-36aa-45f4-a600-8da8e484f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_away_score[average_away_score.index <= 110]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb4852-fd6f-42d1-9e8c-92328dd3e46d",
   "metadata": {},
   "source": [
    "## 6. Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8b561-f451-4edb-95e5-fbdb946950aa",
   "metadata": {},
   "source": [
    "Given our identified task of (insert task here), we selected K-Nearest Neighbors, Logistic Regression, and Random Forest models to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcfb9d-40f6-4145-b06c-a58534239bb8",
   "metadata": {},
   "source": [
    "Here we extract the target values for each instance which will be assigned to the `target` column. These are computed based on the values of the `home_score` and `away_score` columns where:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd23172-fa43-4def-8de6-55ede21ca638",
   "metadata": {},
   "source": [
    "1. If `home_score` > `away_score`, `target` = \"Home Advantage\"\n",
    "2. Else if `home_score` < `away_score`, `target` = \"Away Advantage\"\n",
    "3. Else `target` = \"Balanced\" (indicating that the scores are equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e455fb-7446-4fbb-8477-312f2ba893c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = np.where(data['home_score'] > data['away_score'], \"Home Advantage\", np.where(data['home_score'] < data['away_score'], \"Away Advantage\", \"Balanced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13af625-1b1f-4b2d-8ae6-828696a4e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffeab31-8b03-46c0-b21e-b717d1faac57",
   "metadata": {},
   "source": [
    "In order for the model to make predictions based on the other features of the game, the `home_score` and `away_score` columns are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20efe70-9530-4aa3-b34b-b9a97e29acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"home_score\", \"away_score\"], axis=1, inplace=True)\n",
    "data = data[data['target'] != 'Balanced']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ea5c0-1283-4254-84e0-a82b69d357c3",
   "metadata": {},
   "source": [
    "After establishing the target values, the data is split into the feature matrix and target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b42b66-031a-424e-b418-f305e7c95967",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fb400-e9e5-47bc-9770-ac9a627eec19",
   "metadata": {},
   "source": [
    "To maintain consistency among outputs of various operations, a random seed or state is identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604ed94-880f-4d94-adc2-e3ad3450d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d965d5-30bb-44d3-a912-8e0295bfa649",
   "metadata": {},
   "source": [
    "We defined a function to compute accuracy as this will be used often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b885b43-5f9c-42f7-a877-457cc1ef18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    return round(((predictions == actual).sum() / actual.size) * 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6234a0-c9f7-4942-9a64-fd64ae4e327c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6568da-8d3b-4b90-92c6-612a6431e363",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) is a simple and effective algorithm for classification. KNN predicts the label of a new data point by locating the K-nearest neighbors to a given data point and utilizing their labels. KNN is an excellent choice for this assignment since it can manage non-linear correlations between predictor and outcome variables. Furthermore, KNN is a basic algorithm that is straightforward to build and comprehend. To achieve the best results, it is critical to select an acceptable value of K and distance measure (LaViale, 2023)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979e8d0-3c6b-4c31-afb3-b834c53e35af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### K-Nearest Neighbors Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00331660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import knn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33aec05",
   "metadata": {},
   "source": [
    "We need to standardize the data as there are features on different scales, which may affect the output. We observed that there was a slight increase in accuracy when we standardized the data compared to the unstandardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe23afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbfafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize knn\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions_train = knn_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of predictions on training data\n",
    "acc = compute_accuracy(predictions_train, y_train)\n",
    "print(\"Accuracy of prediction on training data: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test and \n",
    "predictions_test = knn_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy of predictions on training data\n",
    "acc = compute_accuracy(predictions_test, y_test)\n",
    "print(\"Accuracy of prediction on training data: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e955d-55af-4848-a59b-cd74d47aa66f",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "scores = np.zeros((len(k_choices), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models\n",
    "for i in range(len(k_choices)):\n",
    "    print(\"k is : \" + str(k_choices[i]))\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=k_choices[i])\n",
    "\n",
    "    scores[i] = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff53f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def plot_scatter(scores):\n",
    "    for i in range(len(scores)):\n",
    "        x=[k_choices[i]] * 5\n",
    "        plt.scatter(x, scores[i])\n",
    "        \n",
    "plot_scatter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and std and plot\n",
    "avg_scores = np.mean(scores, axis=1)\n",
    "stddev_scores = np.std(scores, axis=1)\n",
    "\n",
    "plot_scatter(scores)\n",
    "\n",
    "plt.errorbar(k_choices, avg_scores, yerr=stddev_scores)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')#### K-Nearest Neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72574b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Now get the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = best_k)\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = compute_accuracy(y_predicted, y_test)\n",
    "num_correct= np.sum(y_test == y_predicted)\n",
    "num_test = y_test.size\n",
    "\n",
    "print(\"Got %d / %d correct => accuracy: %f\" % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e745415",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = {'n_neighbors': np.arange(1, 200, 1)}\n",
    "\n",
    "#Create new KNN object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(estimator=knn, param_grid=hyperparameters, cv=10, scoring='accuracy',error_score=0)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_k = best_model.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "print('Best n_neighbors:', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = best_k)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_predicted = knn.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = compute_accuracy(y_predicted, y_test)\n",
    "num_correct= np.sum(y_test == y_predicted)\n",
    "num_test = y_test.size\n",
    "\n",
    "print(\"Got %d / %d correct => accuracy: %f\" % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3917424-f55e-4b87-9328-25de576467c5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6d841-5411-4e12-bc60-5df72b180201",
   "metadata": {},
   "source": [
    "TODO: justify why logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af237980-bd79-4d62-bcdf-eb3c5bfb5614",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e698120-8e60-45a6-a164-c10a97224ac5",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37f5f8-bba3-44f0-995d-02011f53030c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4de93-5005-40ae-b250-c1bfab081221",
   "metadata": {},
   "source": [
    "For the third model, random forest was chosen for its benefits including being less prone to overfitting, and being able to extract the importances of each feature used in training *(What is Random Forest?, n.d.)*. Given that random forest extends decision trees' predictive power by taking the average of multiple trees, it better captures the general trend of the provided training data. Additionally, by knowing which features have higher importance in influencing the model's predictions, feature selection could happen where less important features can be removed, resulting in a less complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba26ae4-3a80-4ee1-a24d-de2b2990beb0",
   "metadata": {},
   "source": [
    "#### Random Forest Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42775a1-c3c4-4bcb-9985-90428eb3578f",
   "metadata": {},
   "source": [
    "To begin training, the feature matrix and target vector are split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d59ba-2254-4df1-8f7a-cb39a33f3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de81ff-5d29-488b-88ac-f5272a57ade6",
   "metadata": {},
   "source": [
    "A `RandomForestClassifer` object is created and trained with default hyperparameters (as documented [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). The following are the hyperparameters (and initial values) we will be working with and tuning later on.\n",
    "\n",
    "- n_estimators = 100\n",
    "- criterion = \"gini\"\n",
    "- min_samples_leaf = 2\n",
    "- max_features = \"sqrt\"\n",
    "- max_samples = None\n",
    "\n",
    "These hyperparameters were selected given that they were described to have most influence on performance and extraction of feature importance *(Probst et al., 2019)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87325d-bd3c-4a46-a9de-72b73618338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f88ad-bc8b-4e10-afaa-ec16e2a54596",
   "metadata": {},
   "source": [
    "Predictions can now be made on both the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bce6f-8b59-4256-9d56-5268e0b5620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = rfc.predict(X_train)\n",
    "acc_train_rf = compute_accuracy(predictions_train, y_train)\n",
    "print(\"Random forest classifier train accuracy:\", acc_train_rf, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117ee47-94e1-4440-aae7-496f959a613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = rfc.predict(X_test)\n",
    "acc_test_rf = compute_accuracy(predictions_test, y_test)\n",
    "print(\"Random forest classifier test accuracy:\", acc_test_rf, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f77bbb-e6a1-4b02-adee-739ae09055af",
   "metadata": {},
   "source": [
    "The above accuracies show that the model performs very well on the training set but performs poorly on the test set. This shows that the model has **high variance** and is **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce3523-c301-45aa-8bbb-7da20fbe6eaf",
   "metadata": {},
   "source": [
    "#### Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28712aa-990d-4507-9955-21b39a6f3a0b",
   "metadata": {},
   "source": [
    "We define the search space for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fcfb5-6c2d-43eb-a181-8c2d2b5c50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_rf = {\n",
    "    'n_estimators': [100, 120, 140, 300],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', None],\n",
    "    'max_samples': uniform(0.1, 0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d81895-fa5d-40b1-beee-d6b0253e7ec4",
   "metadata": {},
   "source": [
    "To tune the hyperparameters of the Random Forest model, the `RandomizedSearchCV` class will be used. We set the the number of combinations to try (n_iter) to `10` and the number of cross valdiation folds to `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f69fe-8aa8-4679-96ac-8e375e60a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsr = RandomizedSearchCV(estimator=rfc, param_distributions=hyperparameters_rf, n_iter=50, cv=7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01dfea-0c8c-49a1-88de-9c1f3e7c3206",
   "metadata": {},
   "source": [
    "The models are then trained on the training data to produce the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac2f06-ec37-4985-a85c-147278cc2e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb47aa-6876-4ebd-b9a7-6636ac263f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_rf_best = rsr.best_params_\n",
    "hyperparameters_rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7facb-9f18-454e-814a-e88001f3ccd8",
   "metadata": {},
   "source": [
    "Based on these hyperparameters, we can access the best estimator using these identified hyperparameters as well as its feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d12e42-73c1-4897-86a2-8b93e1b7173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_rf = rsr.best_estimator_\n",
    "\n",
    "feature_importance = best_estimator_rf.feature_importances_\n",
    "df_rfc_importance = pd.DataFrame(data=feature_importance, index=data.drop([\"target\"], axis=1).columns, columns=[\"importance\"])\n",
    "df_rfc_importance.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e086061-b164-4c72-b6c2-9e39bd1461c6",
   "metadata": {},
   "source": [
    "This shows that the 3 most important features are `home_on_target`, `current_minute`, and `away_on_target` while the 3 least important features are `home_yellow_cards`, `away_red_cards`, `home_red_cards`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b3c11-8444-4a71-a9c4-16ee60e4c8f1",
   "metadata": {},
   "source": [
    "Here are the relevant results and metrics from each iteration of random combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d41a6-a556-46ec-9f35-0722da13f15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsr_results = pd.DataFrame(rsr.cv_results_).sort_values(by=[\"rank_test_score\"])\n",
    "rsr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e67e5c-d4d8-4363-968c-6f513b4d9611",
   "metadata": {},
   "source": [
    "The updated predictions are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b32aa3-e418-490d-95d7-6de90ffdc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_predictions_train = best_estimator_rf.predict(X_train)\n",
    "tuned_acc_train_rf = compute_accuracy(tuned_predictions_train, y_train)\n",
    "print(\"Random forest classifier train accuracy:\", tuned_acc_train_rf, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389d0f9-6e98-4118-a4f8-c1b4ab06be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_predictions_test = best_estimator_rf.predict(X_test)\n",
    "tuned_acc_test_rf = compute_accuracy(tuned_predictions_test, y_test)\n",
    "print(\"Random forest classifier test accuracy:\", tuned_acc_test_rf, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a8ebd-efa5-48fd-81df-b9ba6ec317ef",
   "metadata": {},
   "source": [
    "Compared to the model's initial performance on default hyperparameter values, the variance of the tuned model has lessened given that it performs slightly worse on the training set and slightly better on the test set. Only minimal improvements to prediction accuracy were made using the best hyperparameters identified using the Randomized Search method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebca6a-44c4-4eda-85a8-be7199aa9328",
   "metadata": {},
   "source": [
    "## 7. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65520aca-d789-4902-b379-41a7fe4dc14d",
   "metadata": {},
   "source": [
    "The `RandomizedSearchCV` hyperparameter tuning method was used. The initial hyperparameters were updated to the best ones found as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581267e2-b3b2-4654-9fc9-070901b45bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInitialBestParams(modelName, originalModel, tunedModel, hyperparameterSearchSpace):\n",
    "    print(f\"Initial and Best hyperparameters for {modelName}:\")\n",
    "    params_df = pd.DataFrame({\n",
    "        'Parameter': list(hyperparameterSearchSpace.keys()),\n",
    "        'Initial': [originalModel.get_params()[key] for key in hyperparameterSearchSpace.keys()],\n",
    "        'Best': [tunedModel.get_params()[key] for key in hyperparameterSearchSpace.keys()],\n",
    "    })\n",
    "    return params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a746e8-692d-4b73-86bd-ecd60deb9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace params with knn stuff\n",
    "printInitialBestParams(\"K-Nearest Neighbors\", rfc, best_estimator_rf, hyperparameters_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712103b9-5e55-4f74-9157-ebb1a5536fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace params with Logistic regression stuff\n",
    "printInitialBestParams(\"Logistic Regression\", rfc, best_estimator_rf, hyperparameters_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba333d9-2987-462e-b47a-2d76529c4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "printInitialBestParams(\"Random Forest\", rfc, best_estimator_rf, hyperparameters_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452817dc-c985-4001-a79c-1e40c4c4c8c6",
   "metadata": {},
   "source": [
    "Using the best hyperparameters identified, the following are the accuracies that were computed for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df9432-9c24-48d6-996e-5b09fc699ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with ur own models stuff\n",
    "\n",
    "accuracies = [\n",
    "    ['K-Nearest Neighbors', [acc_train_rf, acc_test_rf], [tuned_acc_train_rf, tuned_acc_test_rf]],\n",
    "    ['Logistic Regression', [acc_train_rf, acc_test_rf], [tuned_acc_train_rf, tuned_acc_test_rf]],\n",
    "    ['Random Forest', [acc_train_rf, acc_test_rf], [tuned_acc_train_rf, tuned_acc_test_rf]]\n",
    "]\n",
    "\n",
    "pd.DataFrame(accuracies, columns=[\"Model\",\"Initial (Train, Test)\", \"Best (Train, Test)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bcdce-7dd6-43ee-8179-2a0892453559",
   "metadata": {},
   "source": [
    "Based on these accuracies, we conclude that the (insert model) model is the best suited for the identified task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff5093-f1a1-4193-9365-3f3764f93d46",
   "metadata": {},
   "source": [
    "## 8. Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1bc73-5f82-4718-9640-43b7f74e6d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd8dec4-a413-4639-b799-f6cc01e9b3cc",
   "metadata": {},
   "source": [
    "## 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e46a8-d10e-47b9-804f-3f08b44095ab",
   "metadata": {},
   "source": [
    "Probst, P., Wright, M. N., & Boulesteix, A. (2019). Hyperparameters and tuning strategies for Random Forest. WIREs Data Mining and Knowledge Discovery, 9(3). https://doi.org/10.1002/widm.1301 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18edb3c2-eb97-4372-b724-4695da880618",
   "metadata": {},
   "source": [
    "What is Random Forest?. IBM. (n.d.). https://www.ibm.com/topics/random-forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a855e-306f-41fd-b730-8c10d3ff0cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
