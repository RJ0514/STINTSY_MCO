{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb94d1a1-2c72-4734-aed4-10c1b1090c84",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# STINTSY Major Course Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81d6ae-d979-40f2-8d78-d038dd3f01a5",
   "metadata": {},
   "source": [
    "*S12 - Ryan Jay Deculawan, Hyenne Audrey Lim, Viktoria Lila Sicuan*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4365c86-4bf7-411c-b8e0-b4f55050d31f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a4ca9",
   "metadata": {},
   "source": [
    "Soccer's extraordinary global appeal, with 3.5 billion supporters worldwide, cements its position as the most watched sport on the planet. Soccer creates a common passion that brings people from all walks of life together (The Most Popular Sports In The World, n.d.). This worldwide sport has the remarkable potential to cross cultural, language, and geographical borders, bringing people together from all walks of life. Fans congregate in their homes, bars, or stadiums to form a feeling of community and shared identity. Soccer's ongoing popularity stems from its capacity to bring together people of all ages and skill levels, making it more than simply a game but a celebration of athleticism, teamwork, and the universal spirit of competitiveness.\n",
    "\n",
    "Soccer's enormous commercial worth is clear in the huge sums it earns for numerous leagues throughout the world. Soccer leagues have the highest TV viewership of any sports league, which contributes greatly to the sport's economic supremacy. The World Cup, the flagship event, is the embodiment of this phenomena, easily outshining every other significant athletic event. The tremendous viewership and worldwide influence of the World Cup highlight soccer's power to captivate the collective interest and intrigue of audiences on an unprecedented scale, transforming it into more than simply a game but a global cultural phenomenon. Soccer's economic impact, paired with its exciting dynamics, solidifies it as a sporting superpower that crosses geographical and cultural barriers (The World’s Most Watched Sports, 2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939a712",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36dbb7",
   "metadata": {},
   "source": [
    "Home advantage, which occurs in all sports, including soccer, is caused by a mix of psychological and physiological variables. The presence of ardent supporters fosters a supportive and motivational environment for the home side while perhaps influencing referee decisions owing to crowd reactions. Furthermore, the physical and emotional exhaustion involved with travel for visiting teams contributes to the home edge. The familiarity with the particular qualities of the home field, like as pitch size and surface, further tilts the scale in favor of the home side. Home advantage is essentially a complicated interaction of crowd support, referee dynamics, travel-related obstacles, and field familiarity that shapes the competitive landscape of sports (Zheng, 2015).\n",
    "\n",
    "With this in mind, our objective is to investigate the feasibility of forecasting home advantage based on a snapshot of soccer matches. This project intends to emphasize the complex problems of applying modeling tools to real-life events, particularly in the dynamic environment of soccer matches. These machine learning models can help teams plan better strategies by offering insights into their opponents' strengths and weaknesses, such as knowing whether it is strategically better to play aggressively given the statistics of the match. Fans may also appreciate the game on a whole new level through the analysis of data and understanding the aspects that contribute to a team's success. Furthermore, predictive models can assist spectators in making better educated predictions about the outcome of a game, which can increase the enjoyment of watching the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36522c-4923-4d58-90f0-7644b24712d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Description of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940fb74f-8a1d-4d0c-8274-124d3aa71107",
   "metadata": {},
   "source": [
    "To address the identified task, the Sports dataset was selected. This dataset contains 7000 random snapshots from soccer matches. This dataset was used as part of a [Kaggle Community Prediction Competition](https://www.kaggle.com/competitions/sports-trading-will-there-be-more-goals/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7c726-84a7-4aaf-99a0-14085002210c",
   "metadata": {},
   "source": [
    "One row in the dataset represents one snapshot of a match while one column represents one feature of a match. As mentioned, there are **7000 instances** (rows), and **21 features** (columns). The features of the dataset are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac7785-ac2a-4cc9-898f-1f4c1cb8f9de",
   "metadata": {},
   "source": [
    "1. `uuid` - The unique identifier of the snapshot\n",
    "2. `current_minute` - The current minute of the in-play match. The 15 minute half-time break is included so a match has a total of 105 minutes. A current_minute of 70 corresponds to the actual match time of 55.\n",
    "3. `home_score` - Goals scored by the home team as of this current_minute\n",
    "4. `away_score`– Goals scored by the away team as of this current_minute\n",
    "5. `home_yellow_cards` - Yellow cards given to the home team as of this current_minute\n",
    "6. `away_yellow_cards` - Yellow cards given to the away team as of this current_minute\n",
    "7. `home_red_cards` - Red cards given to the home team as of this current_minute\n",
    "8. `away_red_cards` - Red cards given to the away team as of this current_minute\n",
    "9. `home_attacks` - Attacks attempted by the home team as of this current_minute\n",
    "10. `away_attacks` - Attacks attempted by the away team as of this current_minute\n",
    "11. `home_dangerous_attacks` - Dangerous attacks attempted by the home team as of this current_minute\n",
    "12. `away_dangerous_attacks` - Dangerous attacks attempted by the away team as of this current_minute\n",
    "13. `home_corners` - Corners awarded to the home team as of this current_minute\n",
    "14. `away_corners` - Corners awarded to the away team as of this current_minute\n",
    "15. `home_off_target` - Shots that didn't have to be cleared by the goalkeeper that were attempted to the home team as of this current_minute\n",
    "16. `away_off_target` - Shots that didn't have to be cleared by the goalkeeper that were attempted to the away team as of this current_minute\n",
    "17. `home_on_target` - Shots that had to be cleared by the goalkeeper that were attempted to the home team as of this current_minute`\n",
    "18. `away_on_target` - Shots that had to be cleared by the goalkeeper that were attempted to the away team as of this current_minute`\n",
    "19. `home_possession` - How much ball possession in % did the home team have until this current_minute`\n",
    "20. `away_possession` - How much ball possession in % did the away team have until this current_minute`\n",
    "21. `final_delta` - The intended target value for each instance. Given that this dataset is from a competition, this column was provided as the value to be predicted for an instance's set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfea645-5ad4-4d0e-acb9-7771d6cfac9f",
   "metadata": {},
   "source": [
    "## 3. List of Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bab29a-9e5c-44dc-8ccb-0bf133afa645",
   "metadata": {},
   "source": [
    "The following are the libraries and modules used to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378037d8-a942-44c8-8358-2bbe9309016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69d729-f8c9-4663-b858-ccf8a5117846",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4. Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc781cb-e608-4121-a860-5c602696544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "data = pd.read_csv('sports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215f07e-2b66-49c6-98ac-c171c3effcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62a082-8c7e-4f85-8148-0c732cbc4213",
   "metadata": {},
   "source": [
    "Given that the `final_delta` and `uuid` columns do not contribute to the characterization of each soccer match timestamp, these are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86226506-6980-4144-b025-1aabeddaccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"uuid\", \"final_delta\"], axis=1, inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfd12a-cd63-49a0-a83f-f84e696b4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 14 instances where the current minute is <0. \n",
    "#Given that these are only 14, and our total data size is 7000, we can opt to remove them.\n",
    "\n",
    "#First: Collect the indexes of the to-be-removed rows\n",
    "indices = list(data[data['current_minute'] < 0].index)\n",
    "\n",
    "#Second: remove the rows using .drop \n",
    "data = data.drop(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96fe26-d9be-4166-a4b3-20850160d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, lets check, if these outliers are still present.\n",
    "data[data['current_minute'] < 0]\n",
    "#Hooray (dejk) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358548c0-c29c-4d27-9acc-46f4b3c38f27",
   "metadata": {},
   "source": [
    "TODO: *Perform preprocessing and cleaning; move dropping < 0 minute rows here etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f28394-c7c9-46c7-8c7f-41d3cf221c84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34e61e",
   "metadata": {},
   "source": [
    "In this section, we will perform Exploratory Data Analysis to gain insights into the distribution and characteristics of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c6bb4",
   "metadata": {},
   "source": [
    "In this section, we will analyze the trend of each feature to the labels (genres) with 4 levels of Univariate analysis. To further understand the sampled data, we used graphs to show the shape of the distribution, its central value, and its variability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc902f",
   "metadata": {},
   "source": [
    "**Central Tendencies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa5d61",
   "metadata": {},
   "source": [
    "| Measure   | Description                                           |\n",
    "|-----------|-------------------------------------------------------|\n",
    "| Mean      | The average value of the dataset.                     |\n",
    "| Median    | The middle value of the dataset, less sensitive to outliers. |\n",
    "| Mode      | The most frequently occurring value in the dataset.   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63509e-0668-4427-ad47-0c26ea5228d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculating for Central Tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d876729-7390-4b1e-9455-d42681fc51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_tendencies = pd.DataFrame({\n",
    "    'Mean': data.iloc[:, 1:].mean(),\n",
    "    'Median': data.iloc[:, 1:].median(),\n",
    "    'Mode': data.iloc[:, 1:].mode().iloc[0]\n",
    "})\n",
    "central_tendencies = central_tendencies.reset_index()\n",
    "central_tendencies = central_tendencies.rename(columns={'index': 'Feature'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370a361",
   "metadata": {},
   "source": [
    "central_tendencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f500b2a-18bd-44c6-b59f-d648062011ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Calculating for Dispersion, Skewness, and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9b200-bad5-4309-88a0-91a95d74591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Insert purpose of these 3 \n",
    "    Dispersion\n",
    "        - \n",
    "        -\n",
    "    Skewness\n",
    "        - \n",
    "    Kurtosis\n",
    "        - \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41f132-fc57-4528-b32a-a6909ac3727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for variance and standard deviation\n",
    "dispersion_metrics = pd.DataFrame({\n",
    "    'Variance': data.iloc[:, 1:].var(),\n",
    "    'Standard Deviation': data.iloc[:, 1:].std(),\n",
    "    'Skewness': data.iloc[:, 1:].skew(),\n",
    "    'Kurtosis': data.iloc[:, 1:].kurt()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53046c4d-93cd-40fb-9484-eff413596377",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_metrics = dispersion_metrics.reset_index()\n",
    "dispersion_metrics = dispersion_metrics.rename(columns={'index': 'Feature'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6a273",
   "metadata": {},
   "source": [
    "| Feature                   | Range | Variance    | Std Deviation |\n",
    "|---------------------------|-------|-------------|---------------|\n",
    "| home_score                | 8     | 1.147086    | 1.071021      |\n",
    "| away_score                | 9     | 0.852598    | 0.923362      |\n",
    "| home_yellow_cards         | 8     | 0.851639    | 0.922843      |\n",
    "| away_yellow_cards         | 8     | 1.037516    | 1.018586      |\n",
    "| home_red_cards            | 2     | 0.009505    | 0.097496      |\n",
    "| away_red_cards            | 2     | 0.015786    | 0.125644      |\n",
    "| home_attacks              | 255   | 1296.518367 | 36.007199     |\n",
    "| away_attacks              | 183   | 1117.694757 | 33.431942     |\n",
    "| home_dangerous_attacks    | 134   | 528.055699  | 22.979463     |\n",
    "| away_dangerous_attacks    | 140   | 418.592882  | 20.459543     |\n",
    "| home_corners              | 16    | 6.077671    | 2.465293      |\n",
    "| away_corners              | 18    | 4.833917    | 2.198617      |\n",
    "| home_off_target           | 24    | 9.963258    | 3.156463      |\n",
    "| away_off_target           | 18    | 7.553622    | 2.748385      |\n",
    "| home_on_target            | 22    | 5.387207    | 2.321036      |\n",
    "| away_on_target            | 19    | 4.108148    | 2.026857      |\n",
    "| home_possession           | 100   | 109.897919  | 10.483221     |\n",
    "| away_possession           | 100   | 109.940000  | 10.485228     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db360f",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "- Metrics related to scores, cards, attacks, corners, and possession exhibit variations, emphasizing the diverse nature of football match dynamics.\n",
    "- Similar ranges across various metrics suggest balanced competition between home and away teams in different aspects of the game.\n",
    "- The low variability in red cards indicates infrequent occurrences, while other metrics show more variability, reflecting the dynamic nature of certain aspects of football matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc6dbb1",
   "metadata": {},
   "source": [
    "**Skewness and Kurtosis**\n",
    "\n",
    "| Measure  | Description                                           |\n",
    "|----------|-------------------------------------------------------|\n",
    "| Skewness | Measures the asymmetry of the distribution. A skewness of 0 indicates perfect symmetry. |\n",
    "| Kurtosis | Measures the \"tailedness\" of the distribution. Higher kurtosis indicates heavier tails. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_metrics[['Feature','Skewness','Kurtosis']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fa5ec",
   "metadata": {},
   "source": [
    "| Feature                  | Skewness | Kurtosis    | Interpretation                                       |\n",
    "|--------------------------|----------|-------------|------------------------------------------------------|\n",
    "| home_score               | 1.729078 | 3.941218    | Right-skewed, occasional extreme match scores.       |\n",
    "| away_score               | 1.919960 | 5.296752    | Right-skewed distribution of away team scores.       |\n",
    "| home_yellow_cards        | 2.171094 | 5.799577    | Right-skewed, occasional extreme yellow cards.       |\n",
    "| away_yellow_cards        | 1.981708 | 4.362866    | Right-skewed distribution of away team yellow cards. |\n",
    "| home_red_cards           | 10.684115| 118.146351  | Highly right-skewed and heavy-tailed for red cards.  |\n",
    "| away_red_cards           | 7.997090 | 64.188604   | Right-skewed distribution of away team red cards.    |\n",
    "| home_attacks             | 0.594901 | 0.033739    | Right-skewed, moderately peaked distribution.        |\n",
    "| away_attacks             | 0.544677 | -0.270753   | Right-skewed, moderately peaked away team attacks.   |\n",
    "| home_dangerous_attacks   | 0.815359 | 0.453987    | Right-skewed, occasional extreme dangerous attacks.  |\n",
    "| away_dangerous_attacks   | 0.898193 | 0.707852    | Right-skewed distribution of away team dangerous attacks. |\n",
    "| home_corners             | 1.206750 | 1.407153    | Right-skewed corners distribution with moderately heavy tails. |\n",
    "| away_corners             | 1.459539 | 2.881374    | Right-skewed distribution of away team corners.      |\n",
    "| home_off_target          | 1.275574 | 1.888173    | Right-skewed, moderately heavy tails for off-target shots. |\n",
    "| away_off_target          | 1.322685 | 1.953805    | Right-skewed distribution of away team off-target shots. |\n",
    "| home_on_target           | 1.396636 | 2.873205    | Right-skewed on-target shots distribution.            |\n",
    "| away_on_target           | 1.504663 | 3.274469    | Right-skewed distribution of away team on-target shots. |\n",
    "| home_possession          | -0.042671| 2.192167    | Slightly left-skewed home possession distribution with moderately heavy tails. |\n",
    "| away_possession          | 0.038980 | 2.193025    | Slightly right-skewed away possession distribution with moderately heavy tails. |\n",
    "\n",
    "**Insights:**\n",
    "\n",
    "- Features related to scoring, cards, and attacks exhibit right-skewed distributions with occasional extreme values.\n",
    "- Possession metrics show a relatively balanced distribution with moderately heavy tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef0a7a",
   "metadata": {},
   "source": [
    "#### Histogram for Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a488189f",
   "metadata": {},
   "source": [
    "To enhance the visualization of features, create a function called `plot_histogram` that accepts any column name and generates a histogram for that specific column. The function produces the histogram as its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(col_name, bin_count = 5):\n",
    "    data_for_hist = data[col_name]\n",
    "    plt.hist(data_for_hist, bins=bin_count, edgecolor='black')\n",
    "\n",
    "    # Add labels and a title\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of '+col_name)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f8305",
   "metadata": {},
   "source": [
    "Example for histogram:\n",
    "Check the distribution of the current_minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram('current_minute',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['home_red_cards'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba1113",
   "metadata": {},
   "source": [
    "Since we're focusing on home advantage, we can explore the home and away scores further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f474f6",
   "metadata": {},
   "source": [
    "**Task:** Given the current minute, what is the average home score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbfa1b",
   "metadata": {},
   "source": [
    "best_params leverage the `groupby` method in DataFrames to group the data based on 'current_minute'. Subsequently, we compute the average home score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_home_score = data.groupby('current_minute')['home_score'].mean()\n",
    "average_away_score = data.groupby('current_minute')['away_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6576c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'current_minute' values and the corresponding averages for home score\n",
    "minutes_home = average_home_score[average_home_score.index <= 110].index\n",
    "average_scores_home = average_home_score[average_home_score.index <= 110].values\n",
    "\n",
    "# Extract the 'current_minute' values and the corresponding averages for away score\n",
    "minutes_away = average_away_score[average_away_score.index <= 110].index\n",
    "average_scores_away = average_away_score[average_away_score.index <= 110].values\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot for Average Home Score\n",
    "axs[0].plot(minutes_home, average_scores_home, marker='o', linestyle='-')\n",
    "axs[0].set_xlabel('Current Minute')\n",
    "axs[0].set_ylabel('Average Home Score')\n",
    "axs[0].set_title('Average Home Score Over Time')\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot for Average Away Score\n",
    "axs[1].plot(minutes_away, average_scores_away, marker='o', linestyle='-')\n",
    "axs[1].set_xlabel('Current Minute')\n",
    "axs[1].set_ylabel('Average Away Score')\n",
    "axs[1].set_title('Average Away Score Over Time')\n",
    "axs[1].grid()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb4852-fd6f-42d1-9e8c-92328dd3e46d",
   "metadata": {},
   "source": [
    "## 6. Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa8b561-f451-4edb-95e5-fbdb946950aa",
   "metadata": {},
   "source": [
    "Given our identified task of (insert task here), we selected K-Nearest Neighbors, Logistic Regression, and Random Forest models to address this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcfb9d-40f6-4145-b06c-a58534239bb8",
   "metadata": {},
   "source": [
    "Here we extract the target values for each instance which will be assigned to the `target` column. These are computed based on the values of the `home_score` and `away_score` columns where:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd23172-fa43-4def-8de6-55ede21ca638",
   "metadata": {},
   "source": [
    "1. If `home_score` > `away_score`, `target` = \"Home Advantage\"\n",
    "2. Else if `home_score` < `away_score`, `target` = \"Away Advantage\"\n",
    "3. Else `target` = \"Balanced\" (indicating that the scores are equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e455fb-7446-4fbb-8477-312f2ba893c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = np.where(data['home_score'] > data['away_score'], \"Home Advantage\", np.where(data['home_score'] < data['away_score'], \"Away Advantage\", \"Balanced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13af625-1b1f-4b2d-8ae6-828696a4e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fb400-e9e5-47bc-9770-ac9a627eec19",
   "metadata": {},
   "source": [
    "To maintain consistency among outputs of various operations, a random seed or state is identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604ed94-880f-4d94-adc2-e3ad3450d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d965d5-30bb-44d3-a912-8e0295bfa649",
   "metadata": {},
   "source": [
    "We defined a function to compute accuracy as this will be used often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b885b43-5f9c-42f7-a877-457cc1ef18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    return round(((predictions == actual).sum() / actual.size) * 100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6234a0-c9f7-4942-9a64-fd64ae4e327c",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6568da-8d3b-4b90-92c6-612a6431e363",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN) is a simple and effective algorithm for classification. KNN predicts the label of a new data point by locating the K-nearest neighbors to a given data point and utilizing their labels. KNN is an excellent choice for this assignment since it can manage non-linear correlations between predictor and outcome variables. Furthermore, KNN is a basic algorithm that is straightforward to build and comprehend. To achieve the best results, it is critical to select an acceptable value of K and distance measure (LaViale, 2023)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979e8d0-3c6b-4c31-afb3-b834c53e35af",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00331660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import knn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33aec05",
   "metadata": {},
   "source": [
    "We need to standardize the data as there are features on different scales, which may affect the output. We observed that there was a slight increase in accuracy when we standardized the data compared to the unstandardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe23afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cbfafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize knn\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions_train = knn_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of predictions on training data\n",
    "acc = compute_accuracy(predictions_train, y_train)\n",
    "print(\"Accuracy of prediction on training data: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test and \n",
    "predictions_test = knn_classifier.predict(X_test)\n",
    "\n",
    "# Accuracy of predictions on training data\n",
    "acc = compute_accuracy(predictions_test, y_test)\n",
    "print(\"Accuracy of prediction on training data: \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e955d-55af-4848-a59b-cd74d47aa66f",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "scores = np.zeros((len(k_choices), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models\n",
    "for i in range(len(k_choices)):\n",
    "    print(\"k is : \" + str(k_choices[i]))\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=k_choices[i])\n",
    "\n",
    "    scores[i] = cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff53f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "def plot_scatter(scores):\n",
    "    for i in range(len(scores)):\n",
    "        x=[k_choices[i]] * 5\n",
    "        plt.scatter(x, scores[i])\n",
    "        \n",
    "plot_scatter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9572e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and std and plot\n",
    "avg_scores = np.mean(scores, axis=1)\n",
    "stddev_scores = np.std(scores, axis=1)\n",
    "\n",
    "plot_scatter(scores)\n",
    "\n",
    "plt.errorbar(k_choices, avg_scores, yerr=stddev_scores)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')#### K-Nearest Neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72574b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Now get the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = best_k)\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = compute_accuracy(y_predicted, y_test)\n",
    "num_correct= np.sum(y_test == y_predicted)\n",
    "num_test = y_test.size\n",
    "\n",
    "print(\"Got %d / %d correct => accuracy: %f\" % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e745415",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = {'n_neighbors': np.arange(1, 200, 1)}\n",
    "\n",
    "#Create new KNN object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Use GridSearch\n",
    "clf = GridSearchCV(estimator=knn, param_grid=hyperparameters, cv=10, scoring='accuracy',error_score=0)\n",
    "\n",
    "#Fit the model\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_k = best_model.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "print('Best n_neighbors:', best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = best_k)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_predicted = knn.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = compute_accuracy(y_predicted, y_test)\n",
    "num_correct= np.sum(y_test == y_predicted)\n",
    "num_test = y_test.size\n",
    "\n",
    "print(\"Got %d / %d correct => accuracy: %f\" % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3917424-f55e-4b87-9328-25de576467c5",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the RandomizedSearchCV, Logistic Regression, and some methods we will use for the metrics of our results. With this, we will be able to fit, predict, get the accuracy of the dataset and its labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d6d841-5411-4e12-bc60-5df72b180201",
   "metadata": {},
   "source": [
    "TODO: justify why logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af237980-bd79-4d62-bcdf-eb3c5bfb5614",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['home_score','away_score','target'], axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_train)\n",
    "accuracy_score(y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag'],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000, 10000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "rsr = RandomizedSearchCV(estimator = model, param_distributions=param_grid, cv = 5, random_state = 42, n_iter = 50)\n",
    "rsr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell above performs the RandomizedSearchCV to hypertune the Logistic Regression classifier. Now, let's output the best parameters from the Randomized search hypertuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and the best model\n",
    "best_params = rsr.best_params_\n",
    "best_model = rsr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us predict and check the score of the predictions against the validation set using our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = best_model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the accuracy  and check the score of the predictions against the validation set using our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = accuracy_score(y_validation, y_val_pred)\n",
    "val_report = classification_report(y_validation, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "val_accuracy = accuracy_score(y_validation, y_val_pred)\n",
    "\n",
    "# Generate the classification report as a dictionary\n",
    "val_report_dict = classification_report(y_validation, y_val_pred, output_dict=True)\n",
    "\n",
    "# Convert the classification report dictionary to a DataFrame\n",
    "val_report_df = pd.DataFrame(val_report_dict).transpose()\n",
    "\n",
    "# Print the results\n",
    "print(\"Validation Set Results:\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "val_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "  - The model performs best for the \"Balanced\" class, indicating good precision, recall, and F1-Score.\n",
    "  - The model struggles with precision for the \"Away Advantage\" class, indicating a higher rate of false positives.\n",
    "  - A balanced F1-Score suggests that the model maintains a reasonable trade-off between precision and recall across classes.\n",
    "  - The weighted average F1-Score (0.5867) reflects an overall decent performance, considering the class distribution.\n",
    "\n",
    "**Recommendations:**\n",
    "  - Further investigate and potentially address the false positives in predicting \"Away Advantage.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try our trained model on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the prediction results on the test data to see if our model can handle unseen instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Generate the classification report as a dictionary\n",
    "test_report_dict = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "# Convert the classification report dictionary to a DataFrame\n",
    "test_report_df = pd.DataFrame(test_report_dict).transpose()\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "test_report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**\n",
    "  - The model performs well in distinguishing between \"Home Advantage\" and \"Away Advantage\" classes, with high precision and recall values for both.\n",
    "  - A balanced F1-Score suggests that the model maintains a reasonable trade-off between precision and recall across classes.\n",
    "  - The weighted average F1-Score (0.7814) reflects an overall strong performance, considering the class distribution in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37f5f8-bba3-44f0-995d-02011f53030c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4de93-5005-40ae-b250-c1bfab081221",
   "metadata": {},
   "source": [
    "For the third model, random forest was chosen for its benefits including being less prone to overfitting, and being able to extract the importances of each feature used in training *(What is Random Forest?, n.d.)*. Given that random forest extends decision trees' predictive power by taking the average of multiple trees, it better captures the general trend of the provided training data. Additionally, by knowing which features have higher importance in influencing the model's predictions, feature selection could happen where less important features can be removed, resulting in a less complex model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba26ae4-3a80-4ee1-a24d-de2b2990beb0",
   "metadata": {},
   "source": [
    "#### Random Forest Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42775a1-c3c4-4bcb-9985-90428eb3578f",
   "metadata": {},
   "source": [
    "To begin training, irrelevant rows and columns the feature matrix and target vector are split into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20efe70-9530-4aa3-b34b-b9a97e29acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = data.drop([\"home_score\", \"away_score\"], axis=1)\n",
    "rf_data = rf_data[rf_data['target'] != 'Balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0b3656-9823-452d-943c-08d5d4baaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rf_data.iloc[:, :-1].values\n",
    "y = rf_data.iloc[:, -1].values\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d59ba-2254-4df1-8f7a-cb39a33f3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de81ff-5d29-488b-88ac-f5272a57ade6",
   "metadata": {},
   "source": [
    "A `RandomForestClassifer` object is created and trained with default hyperparameters (as documented [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). The following are the hyperparameters (and initial values) we will be working with and tuning later on.\n",
    "\n",
    "- n_estimators = 100\n",
    "- criterion = \"gini\"\n",
    "- min_samples_leaf = 2\n",
    "- max_features = \"sqrt\"\n",
    "- max_samples = None\n",
    "\n",
    "These hyperparameters were selected given that they were described to have most influence on performance and extraction of feature importance *(Probst et al., 2019)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c87325d-bd3c-4a46-a9de-72b73618338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f88ad-bc8b-4e10-afaa-ec16e2a54596",
   "metadata": {},
   "source": [
    "Predictions can now be made on both the training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bce6f-8b59-4256-9d56-5268e0b5620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = rfc.predict(X_train)\n",
    "acc_train_rf = compute_accuracy(predictions_train, y_train)\n",
    "print(\"Random forest classifier train accuracy:\", acc_train_rf, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117ee47-94e1-4440-aae7-496f959a613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = rfc.predict(X_test)\n",
    "acc_test_rf = compute_accuracy(predictions_test, y_test)\n",
    "print(\"Random forest classifier test accuracy:\", acc_test_rf, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f77bbb-e6a1-4b02-adee-739ae09055af",
   "metadata": {},
   "source": [
    "The above accuracies show that the model performs very well on the training set but performs poorly on the test set. This shows that the model has **high variance** and is **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce3523-c301-45aa-8bbb-7da20fbe6eaf",
   "metadata": {},
   "source": [
    "#### Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28712aa-990d-4507-9955-21b39a6f3a0b",
   "metadata": {},
   "source": [
    "We define the search space for hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fcfb5-6c2d-43eb-a181-8c2d2b5c50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_rf = {\n",
    "    'n_estimators': [100, 120, 140, 300],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', None],\n",
    "    'max_samples': uniform(0.1, 0.9)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d81895-fa5d-40b1-beee-d6b0253e7ec4",
   "metadata": {},
   "source": [
    "To tune the hyperparameters of the Random Forest model, the `RandomizedSearchCV` class will be used. We set the the number of combinations to try (n_iter) to `30` and the number of cross valdiation folds to `7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f69fe-8aa8-4679-96ac-8e375e60a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsr = RandomizedSearchCV(estimator=rfc, param_distributions=hyperparameters_rf, n_iter=50, cv=7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01dfea-0c8c-49a1-88de-9c1f3e7c3206",
   "metadata": {},
   "source": [
    "The models are then trained on the training data to produce the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac2f06-ec37-4985-a85c-147278cc2e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb47aa-6876-4ebd-b9a7-6636ac263f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_rf_best = rsr.best_params_\n",
    "hyperparameters_rf_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7facb-9f18-454e-814a-e88001f3ccd8",
   "metadata": {},
   "source": [
    "Based on these hyperparameters, we can access the best estimator using these identified hyperparameters as well as its feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d12e42-73c1-4897-86a2-8b93e1b7173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_rf = rsr.best_estimator_\n",
    "\n",
    "feature_importance = best_estimator_rf.feature_importances_\n",
    "df_rfc_importance = pd.DataFrame(data=feature_importance, index=data.drop([\"target\"], axis=1).columns, columns=[\"importance\"])\n",
    "df_rfc_importance.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e086061-b164-4c72-b6c2-9e39bd1461c6",
   "metadata": {},
   "source": [
    "This shows that the 3 most important features are `home_on_target`, `current_minute`, and `away_on_target` while the 3 least important features are `home_yellow_cards`, `away_red_cards`, `home_red_cards`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b3c11-8444-4a71-a9c4-16ee60e4c8f1",
   "metadata": {},
   "source": [
    "Here are the relevant results and metrics from each iteration of random combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d41a6-a556-46ec-9f35-0722da13f15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsr_results = pd.DataFrame(rsr.cv_results_).sort_values(by=[\"rank_test_score\"])\n",
    "rsr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e67e5c-d4d8-4363-968c-6f513b4d9611",
   "metadata": {},
   "source": [
    "The updated predictions are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b32aa3-e418-490d-95d7-6de90ffdc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_predictions_train = best_estimator_rf.predict(X_train)\n",
    "tuned_acc_train_rf = compute_accuracy(tuned_predictions_train, y_train)\n",
    "print(\"Random forest classifier train accuracy:\", tuned_acc_train_rf, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3389d0f9-6e98-4118-a4f8-c1b4ab06be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_predictions_test = best_estimator_rf.predict(X_test)\n",
    "tuned_acc_test_rf = compute_accuracy(tuned_predictions_test, y_test)\n",
    "print(\"Random forest classifier test accuracy:\", tuned_acc_test_rf, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a8ebd-efa5-48fd-81df-b9ba6ec317ef",
   "metadata": {},
   "source": [
    "Compared to the model's initial performance on default hyperparameter values, the variance of the tuned model has lessened given that it performs slightly worse on the training set and slightly better on the test set. Only minimal improvements to prediction accuracy were made using the best hyperparameters identified using the Randomized Search method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebca6a-44c4-4eda-85a8-be7199aa9328",
   "metadata": {},
   "source": [
    "## 7. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd05768-2c46-439e-9a8d-8016c198ac95",
   "metadata": {},
   "source": [
    "Here, we exhibit each model's initial configurations and best sets of hyperparameters after tuning. The following are the search spaces defined to find hyperparameters that improve accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65520aca-d789-4902-b379-41a7fe4dc14d",
   "metadata": {},
   "source": [
    "The `RandomizedSearchCV` hyperparameter tuning method was used. The initial hyperparameters were updated to the best ones found as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581267e2-b3b2-4654-9fc9-070901b45bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printInitialBestParams(modelName, originalModel, tunedModel, hyperparameterSearchSpace):\n",
    "    print(f\"Initial and Best hyperparameters for {modelName}:\")\n",
    "    params_df = pd.DataFrame({\n",
    "        'Parameter': list(hyperparameterSearchSpace.keys()),\n",
    "        'Initial': [originalModel.get_params()[key] for key in hyperparameterSearchSpace.keys()],\n",
    "        'Best': [tunedModel.get_params()[key] for key in hyperparameterSearchSpace.keys()],\n",
    "    })\n",
    "    return params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a746e8-692d-4b73-86bd-ecd60deb9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace params with knn stuff\n",
    "printInitialBestParams(\"K-Nearest Neighbors\", rfc, best_estimator_rf, hyperparameters_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712103b9-5e55-4f74-9157-ebb1a5536fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace params with Logistic regression stuff\n",
    "printInitialBestParams(\"Logistic Regression\", model, model, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba333d9-2987-462e-b47a-2d76529c4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "printInitialBestParams(\"Random Forest\", rfc, best_estimator_rf, hyperparameters_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452817dc-c985-4001-a79c-1e40c4c4c8c6",
   "metadata": {},
   "source": [
    "Using the best hyperparameters identified, the following are the accuracies that were computed for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df9432-9c24-48d6-996e-5b09fc699ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with ur own models stuff\n",
    "\n",
    "accuracies = [\n",
    "    ['K-Nearest Neighbors', [acc_train_rf, acc_test_rf], [tuned_acc_train_rf, tuned_acc_test_rf]],\n",
    "    ['Logistic Regression', [acc_train_rf, acc_test_rf], [tuned_acc_train_rf, tuned_acc_test_rf]],\n",
    "    ['Random Forest', [acc_train_rf, acc_test_rf], [tuned_acc_train_rf, tuned_acc_test_rf]]\n",
    "]\n",
    "\n",
    "pd.DataFrame(accuracies, columns=[\"Model\",\"Initial (Train, Test)\", \"Best (Train, Test)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bcdce-7dd6-43ee-8179-2a0892453559",
   "metadata": {},
   "source": [
    "Based on these accuracies, we conclude that the (insert model) model is the best suited for the identified task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff5093-f1a1-4193-9365-3f3764f93d46",
   "metadata": {},
   "source": [
    "## 8. Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756c595-8f39-435b-a6ec-45cce525b496",
   "metadata": {},
   "source": [
    "For Random Forest, despite being designed to mitigate overfitting, both the default hyperparameter configuration and the model fine-tuned with the best-found hyperparameters still demonstrate overfitting tendencies, as shown by relatively lower prediction accuracy on the test set compared to the training set. To address this, an examination of feature importances revealed that certain features may not significantly contribute to the model's performance. Consequently, a potential enhancement involves considering the removal of features with limited influence. Moreover, the process of hyperparameter tuning involved extensive trial and error within the search space, yielding only marginal improvements. To refine this approach, further exploration of hyperparameter combinations, such as the inclusion of parameters like max depth, could be undertaken to achieve more substantial enhancements in model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8dec4-a413-4639-b799-f6cc01e9b3cc",
   "metadata": {},
   "source": [
    "## 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e46a8-d10e-47b9-804f-3f08b44095ab",
   "metadata": {},
   "source": [
    "Probst, P., Wright, M. N., & Boulesteix, A. (2019). Hyperparameters and tuning strategies for Random Forest. WIREs Data Mining and Knowledge Discovery, 9(3). https://doi.org/10.1002/widm.1301 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18edb3c2-eb97-4372-b724-4695da880618",
   "metadata": {},
   "source": [
    "What is Random Forest?. IBM. (n.d.). https://www.ibm.com/topics/random-forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a855e-306f-41fd-b730-8c10d3ff0cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
